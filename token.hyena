enum TokType {
    _plus,
    _minus,
    _multiply,
    _divide,
    _number,
    _undef,
    _leftparen,
    _rightparen,
    _semicolon,
    _colon,
    _identifier,
    _var,
    _equal,
    _leftbrace,
    _rightbrace,
    _bang,
    _greater,
    _less,
    _if,
    _else,
    _while,
    _break,
    _continue,
    _extern,
    _fn,
    _dot,
    _comma,
    _string,
    _return,
    _struct,
    _leftsquare,
    _rightsquare,
    _mod,
    _u8,
    _u16,
    _u32,
    _u64,
    _i8,
    _i16,
    _i32,
    _i64,
    _f32,
    _f64,
    _void,
    _true,
    _false,
    _bool,
    _eq,
    _neq,
    _lte,
    _gte,
    _union,
    _enum,
    _at,
    _and,
    _or,
    _bitxor,
    _bitand,
    _bitor,
    _bitnot,
    _squote,
    _asm,
    _str,
    _undefined,
    _hash,
    _module,
    _impl,
    _doublecolon,
    _import,
    _addeq,
    _muleq,
    _diveq,
    _subeq,
    _modeq,
    _bitandeq,
    _bitoreq,
    _bitxoreq,
    _bitnoteq,
    _shl,
    _shr,
    _shreq,
    _shleq,
    _plong,
    _switch,
    _range,
    _for,
    _pipe,
    _defer,
    _null,
    _cast,
    _argv,
    _bslash,
    _qmark,
    _sizeof,
    _alignof,
    _character,
    _eof
}

struct Token {
    type:   TokType,
    value:  &u8,
    line:   u64,
    col:    u64,
    number: i32
}

var current_line:u64    = 0;
var current_column:u64  = 0;
var current:u64         = 0;
var source_code:&u8 = undefined;
var eof:u8          = -1;

impl Token {
    init(type:TokType, value:&u8) Token {
        return Token {
            .type = type,
            .value = value,
            .line = current_line,
            .col = current_column
        };
    }

}


fn token_error(message:&u8, args:argv) void {
    fmt::print("current_file:%q:%q ", .{current_line, current_column});
    fmt::println(message, args);
    exit(1);
}

fn more_tokens() bool {
    return current < source_code.len;
}

fn advance() void {
    current += 1;
    current_column += 1;
    return source_code[current - 1];
}

fn peek() u8 {
    if(more_tokens()) {
        return source_code[current];
    }
    return eof;
}

fn expect(char:u8) void {
    if(peek() == char) {
        advance();
        return;
    }

    token_error("Epected %b found %b", .{char, peek()});
    exit(1);
}

fn peek_next() u8 {
    if(source_code.len < current+2) return eof;
    return source_code[current+1];
}

fn peek_next_next() u8 {
    if(source_code.len < current+3) return eof;
    return source_code[current+2];
}


struct NTpair {
    key:&u8,
    type:TokType
}

var token_map = []NTpair {
            NTpair { .key = "var",        .type = TokType._var },
            NTpair { .key = "if",         .type = TokType._if },
            NTpair { .key = "else",       .type = TokType._else },
            NTpair { .key = "while",      .type = TokType._while },
            NTpair { .key = "break",      .type = TokType._break },
            NTpair { .key = "continue",   .type = TokType._continue },
            NTpair { .key = "extern",     .type = TokType._extern },
            NTpair { .key = "fn",         .type = TokType._fn },
            NTpair { .key = "return",     .type = TokType._return },
            NTpair { .key = "struct",     .type = TokType._struct },
            NTpair { .key = "void",       .type = TokType._void },
            NTpair { .key = "u8",         .type = TokType._u8 },
            NTpair { .key = "u16",        .type = TokType._u16 },
            NTpair { .key = "u32",        .type = TokType._u32 },
            NTpair { .key = "u64",        .type = TokType._u64 },
            NTpair { .key = "i8",         .type = TokType._i8 },
            NTpair { .key = "i16",        .type = TokType._i16 },
            NTpair { .key = "i32",        .type = TokType._i32 },
            NTpair { .key = "i64",        .type = TokType._i64 },
            NTpair { .key = "true",       .type = TokType._true },
            NTpair { .key = "false",      .type = TokType._false },
            NTpair { .key = "bool",       .type = TokType._bool },
            NTpair { .key = "f32",        .type = TokType._f32 },
            NTpair { .key = "union",      .type = TokType._union },
            NTpair { .key = "enum",       .type = TokType._enum },
            NTpair { .key = "and",        .type = TokType._and },
            NTpair { .key = "or",         .type = TokType._or },
            NTpair { .key = "str",        .type = TokType._str },
            NTpair { .key = "undefined",  .type = TokType._undefined },
            NTpair { .key = "asm",        .type = TokType._asm },
            NTpair { .key = "module",     .type = TokType._module },
            NTpair { .key = "impl",       .type = TokType._impl },
            NTpair { .key = "import",     .type = TokType._import },
            NTpair { .key = "switch",     .type = TokType._switch },
            NTpair { .key = "for",        .type = TokType._for },
            NTpair { .key = "defer",      .type = TokType._defer },
            NTpair { .key = "null",       .type = TokType._null },
            NTpair { .key = "cast",       .type = TokType._cast },
            NTpair { .key = "argv",       .type = TokType._argv },
            NTpair { .key = "sizeof",     .type = TokType._sizeof },
            NTpair { .key = "alignof",    .type = TokType._alignof}
};

fn get_escape() u8 {
    switch(peek_next()) {
        'n' => return '\n';,
        't' => return '\t';,
        '0' => return '\0';,
        'b' => return '\b';,
        'r' => return '\r';,
        else => |char| {
            //token_error("Unknown escape esquence", .{char});
            return char;
        }
    }
}

fn read_string() Token {
    advance();
    var buff:[1024]u8 = undefined;
    var count = 0;
    while(more_tokens() and peek() != '"' and peek() != '\n') {
        if(peek() == '\\') {
            buff[count] = get_escape();
            advance();
        } else {
            buff[count] = peek();
        }
        advance();
        count += 1;
    }
    expect('"');

    var buff_ptr = cast(*u8)malloc(count+1);
    memcpy(buff_ptr, (cast(*u64)&buff)+1, count);
    (buff_ptr + count).* = '\0';
    var slice:&u8 = undefined;
    slice.ptr = buff_ptr;
    slice.len = count;
    var tok = Token::init(TokType._string, slice);
    return tok;
}

fn read_char() Token {
    advance();
    var value:u8 = undefined;
    if(peek() == '\\') {
        value = get_escape();
        advance();
    } else {
        value = peek();
    }
    advance();
    expect('\'');
    var tok = Token::init(TokType._character, "");
    tok.number = value;
    return tok;
}

fn number() Token {
    var start = current;
    while(more_tokens()) {
        if(!strings::is_number(peek())) break;
        advance();
    }
    var tok = Token::init(TokType._number, "");
    tok.number = strings::parse_int(source_code[start..current]);
    return tok;
}

fn match_token(ndle:&u8) TokType {
    for(token_map) |*T| {
        if(strings::compare(ndle, T.key)) {
            return T.type;
        }
    }
    return -1;
}

fn identifier() Token {
    var start = current;
    while(more_tokens()) {
        if(!strings::is_alnum(peek())) break;
        advance();
    }
    var slice = source_code[start..current];
    var type = cast(i32)match_token(slice);
    if(type >= 0) {
        return Token::init(type, slice);
    }
    return Token::init(TokType._identifier, slice);
}

fn skip_comment() void {
    while(more_tokens() and peek() != '\n') advance();
    if(more_tokens()){
        advance();
        current_column = 0;
        current_line += 1;
    }
}

struct TokenArray {
    items:&Token,
    capacity:u64
}

impl TokenArray {
    init() TokenArray {
        var slice:&Token = undefined;
        slice.ptr = null;
        slice.len = 0;
        return TokenArray {
            .items = slice,
            .capacity = 0
        };
    }

    append(self:*TokenArray, tok:Token) void {
        if(self.capacity == self.items.len) {
            var new_ptr = cast(*Token)malloc(self.capacity * sizeof(Token) + 10 *(sizeof(Token)));
            if(self.items.len > 0) {
                memcpy(new_ptr, self.items.ptr, 1);
                free(self.items.ptr);
            }
            self.items.ptr = new_ptr;
            self.capacity += 10;
        }

        self.items[self.items.len] = tok;
        self.items.len += 1;
    }

    add(self:*TokenArray, type:TokType) void {
        self.append(Token::init(type, ""));
    }
}


fn tokenize(code:&u8) TokenArray {
    var tokens = TokenArray::init();
    source_code = code;
    current_line = 0;
    current_column = 0;

    while (true) {
        var curr_char = peek();

        if(strings::is_number(curr_char)) {
            tokens.append(number());
            continue;
        } else if(strings::is_space(curr_char)) {
            if(curr_char == '\n') {
                current_column = 0;
                current_line += 1;
            }
            advance();
            continue;
        } else if(strings::is_alpha(curr_char)) {
            tokens.append(identifier());
            continue;
        } else if(curr_char == '/') {
            if(peek_next() == '/'){
                skip_comment();
                continue;
            } 
        } else if (curr_char == '"') {
            tokens.append(read_string());
            continue;
        } else if(curr_char == '\'') {
            tokens.append(read_char());
            continue;
        }
        
        fmt::println("%b",.{curr_char});

        switch(curr_char) {
            -1 => {
                        tokens.add(TokType._eof);
                        break;
                    },
            '+' => {
                        if(peek() == '=') {
                            tokens.add(TokType._addeq);
                            advance();
                        } else {
                            tokens.add(TokType._plus);
                        }
                    },
            '-' => {
                        if(peek() == '=') {
                            tokens.add(TokType._subeq);
                            advance();
                        } else {
                            tokens.add(TokType._minus);
                        }
                    },
            '/' => {
                        if(peek() == '=') {
                            tokens.add(TokType._diveq);
                            advance();
                        } else {
                            tokens.add(TokType._divide);
                        }
                    },
            '*' => {
                        if(peek() == '=') {
                            tokens.add(TokType._muleq);
                            advance();
                        } else {
                            tokens.add(TokType._multiply);
                        }
                    },
            '>' => {
                        if(peek() == '=') {
                            tokens.add(TokType._gte);
                            advance();
                        } else if(peek_next() == '>') {
                            if(peek_next_next() == '=') {
                                tokens.add(TokType._shreq);
                                advance();
                                advance();
                            } else {
                                tokens.add(TokType._shr);
                                advance();
                            }
                        } else {
                            tokens.add(TokType._greater);
                        }
                    }, 
            '!' => {
                        if(peek() == '=') {
                            tokens.add(TokType._neq);
                            advance();
                        } else {
                            tokens.add(TokType._bang);
                        }
                    },
            '<' => {
                        if(peek() == '=') {
                            tokens.add(TokType._lte);
                            advance();
                        } else if(peek_next() == '<') {
                            if(peek_next_next() == '=') {
                                tokens.add(TokType._shleq);
                                advance();
                                advance();
                            } else {
                                tokens.add(TokType._shl);
                                advance();
                            }
                        } else {
                            tokens.add(TokType._less);
                        }
                    },
            '^' => {
                        if(peek() == '=') {
                            tokens.add(TokType._bitoreq);
                            advance();
                        } else {
                            tokens.add(TokType._bitxor);
                        }
                    },
            '&' => {
                        if(peek() == '=') {
                            tokens.add(TokType._bitandeq);
                            advance();
                        } else {
                            tokens.add(TokType._bitand);
                        }
                    },
            '|' => {
                        if(peek() == '=') {
                            tokens.add(TokType._bitoreq);
                            advance();
                        } else {
                            tokens.add(TokType._bitor);
                        }
                    },
            '~' => {
                        if(peek() == '=') {
                            tokens.add(TokType._bitnoteq);
                        } else {
                            tokens.add(TokType._bitnot);
                        }
                    },
            '=' => {
                        if(peek() == '=') {
                            tokens.add(TokType._eq);
                            advance();
                        } else if(peek() == '>') {
                            tokens.add(TokType._plong);
                            advance();
                        } else {
                            tokens.add(TokType._equal);
                        }
                    },
            ':' => {
                        if(peek() == ':') {
                            tokens.add(TokType._doublecolon);
                            advance();
                        } else {
                            tokens.add(TokType._colon);
                        }
                    },
            '.' => {
                        if(peek() == '.') {
                            tokens.add(TokType._range);
                            advance();
                        } else {
                            tokens.add(TokType._dot);
                        }
                    },
            '{' => tokens.add(TokType._leftbrace);,
            '}' => tokens.add(TokType._rightbrace);,
            '(' => tokens.add(TokType._leftparen);,
            ')' => tokens.add(TokType._rightparen);,
            '[' => tokens.add(TokType._leftsquare);,
            ']' => tokens.add(TokType._rightsquare);,
            '%' => tokens.add(TokType._mod);,
            '?' => tokens.add(TokType._qmark);,
            ',' => tokens.add(TokType._comma);,
            ';' => tokens.add(TokType._semicolon);,
            '|' => tokens.add(TokType._pipe);,
            else => |c| {
                        token_error("Unexpected token %b", .{c});
                        break;
            }

        }

        advance();
    }

    return tokens;
}


import "c.hyena"
import "fmt.hyena"
import "string.hyena"
